---
title: "p8105_hw3_rl3401"
author: "Ruoxi Li"
date: "`r Sys.Date()`"
output: github_document
---
```{r}
library(tidyverse)
```


## Problem 1

```{r}
library(p8105.datasets)
data("instacart")
```

*This is a dataset with `r ncol(instacart)` columns and `r nrow(instacart)` rows. The variables include `r names(instacart)`.*

*Here is an example of observations.*

`r slice(instacart, 1)|>knitr::kable()`

*This means :*

*The user with user_id "112108" has placed an order with order_id "1" . The product "Bulgarian Yogurt" (product_id: 49302) is the first item in the cart. It is categorized under the "yogurt" aisle (aisle_id: 120) within the "dairy eggs" department (department_id: 16).*

*This isn't the user's first time ordering this product. It is the 4th order sequence for the user. The day of the week on which the order was placed is "4", the hour of the day on which the order was placed is "10". It has been 9 days since the user's previous order.*

```{r}
count_aisle = 
  count(instacart,aisle)|>
  arrange(-n)

  head(count_aisle,n=1)
nrow(count_aisle)
```

*There are `r nrow(count_aisle)` aisles, the most items are ordered from the aisle fresh vegetables.*

```{r}
count_aisle |>
  filter(n > 10000)|>
  mutate(aisle = fct_reorder(aisle, -n))|>
  ggplot(aes(x=aisle, y=n))+ 
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Items ordered from each aisle", x = "Aisle", y = "Number of items")
```

*This is a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered.*

```{r}
top_items = instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle, product_name) |>
  summarize(times_ordered = n()) |>
  arrange(aisle, -times_ordered) |>
  slice_head(n = 3) |>
  knitr::kable()
``` 

`r top_items`

*This is a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.*

```{r}
mean_hour = instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
               names_from = order_dow, values_from = mean_hour
  )|>
    knitr::kable()
```

`r mean_hour`

*This is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.*


## problem 2

```{r}
library(p8105.datasets)
data("brfss_smart2010") 
```

```{r}
brfss_df <- brfss_smart2010 |>
  janitor::clean_names() |>
  filter( topic== "Overall Health",
          response %in% c("Excellent","Very good","Good","Fair","Poor")
            ) |>
  mutate(response = factor(response, 
                           levels =c("Poor", "Fair", "Good", "Very good", "Excellent"))
         )
```


```{r}
brfss_df |>
  group_by(year, locationabbr) |>
  summarize(n_locations = n_distinct(locationdesc)) |>
   filter(year == 2002, n_locations >= 7) |>
    arrange(-n_locations)
```

*In 2002, states observed at 7 or more locations were PA, MA, NJ, CT, FL, NC. PA has the most observed locations as 10.*

```{r}
brfss_df |>
  group_by(year, locationabbr) |>
  summarize(n_locations = n_distinct(locationdesc)) |>
   filter(year == 2010, n_locations >= 7) |>
    arrange(-n_locations)
```

*In 2010, states observed at 7 or more locations were FL, NJ, TX, CA, MD, NC, NE, WA, MA, NY, OH, CO, PA,SC. FL has the most observed locations as 41.*

Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state:

```{r}
  brfss_df|>
  filter(response == "Excellent") |>
  group_by(year,locationabbr)|>
  summarize(mean_data_value = mean(data_value, na.rm= TRUE)) |>    
  ggplot(aes(x=year,y=mean_data_value,group=locationabbr,color=locationabbr))+
  geom_line()+
  labs(x = "Year", y = "Average of the data value", title = "“spaghetti” plot of this average value over time within a state ")
```

*This is a “spaghetti” plot of this average value over time within a state limited to Excellent responses. At a glance, there appears to be a consistent trend across states. However, due to the sheer number of overlapping lines representing each state, distinguishing between them becomes challenging. This density impedes a clear and definitive interpretation of the data.*

Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY state:

```{r}
brfss_df |>
  filter(locationabbr == "NY", year %in% c(2006,2010))|>
  ggplot(aes(x = response, y =  data_value)) +
  facet_grid(.~ year) +
  geom_boxplot()
```

or:

```{r}
brfss_df |>
  filter(locationabbr == "NY", year %in% c(2006,2010))|>
  ggplot(aes(x =  data_value, color = response)) +
  geom_density(alpha = 0.5) +
  facet_grid(.~ year) +
  labs(x = "Data Value", y = "Density", title = "Distribution of Data Value by Year in NY State") 
```

## problem 3

Load, tidy, merge, and otherwise organize the data sets:

```{r}
accel_df = read_csv("data/nhanes_accel.csv")|>
  janitor::clean_names()|>
   pivot_longer(
    cols = starts_with("min"),
               names_to = "time",
               values_to = "accel")

covar_df = read_csv("data/nhanes_covar.csv",skip = 4)|>
  janitor::clean_names() |>
  drop_na()|>
  filter(age >= 21)|>
  mutate(
      sex = case_match(
      sex,
      1 ~ "male",
      2 ~ "female"),
      education = case_match(
        education,
        1 ~ "less than high school",
        2 ~ "high school equivalent",
        3 ~ "more than high school"
      ))|>
  mutate(education = fct_relevel(education, "less than high school", "high school equivalent", "more than high school"))

```

Produce a reader-friendly table for the number of men and women in each education category:

```{r}
covar_df |>
  group_by(sex,education)|>
  summarize(n_obs=n())|>
  pivot_wider(
    names_from = education,
    values_from = n_obs
  )|>
  knitr::kable()
```

Create a visualization of the age distributions for men and women in each education category. 

```{r}
covar_df|>
  ggplot(aes(x=age,color=sex))+
  geom_density()+
  facet_grid(.~education)
```

*Comment*

```{r}
total_activity_df = accel_df|>
  group_by(seqn)|>
  summarize(total_activity=sum(accel))
```

Plot - Total activity over the day:

```{r}
total_activity_plot_df = inner_join(covar_df,total_activity_df,by="seqn") 
total_activity_plot_df|>
  ggplot(aes(x=age,y=total_activity,color=sex))+
  facet_grid(.~education)+
  geom_point()+
  geom_smooth()+
   labs(title = "Total activity over the day by education level",
       x = "Age",
       y = "Activity Level",
       color = "Sex") 
```

*comment*

Plot - 24-hour activity time courses：

```{r}

hour24_plot_df = inner_join(covar_df, accel_df, by = "seqn")


hour24_plot_df |>
ggplot( aes(x = time, y = accel, color = sex)) +
  geom_point( alpha = 0.5)   +
  geom_smooth() +
  facet_grid(.~education)+
  labs(title = "24-hour activity time courses by education level",
       x = "Minute",
       y = "Activity Level",
       color = "Sex") 
```

*Describe in words any patterns or conclusions you can make based on this graph*
