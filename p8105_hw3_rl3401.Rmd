---
title: "p8105_hw3_rl3401"
author: "Ruoxi Li"
date: "`r Sys.Date()`"
output: github_document
---
```{r}
library(tidyverse)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1

```{r}
library(p8105.datasets)
data("instacart")
```

*This is a dataset with `r ncol(instacart)` columns and `r nrow(instacart)` rows. The variables include `r names(instacart)`.*

*Here is an example of observations.*

`r slice(instacart, 1)|>knitr::kable()`

*This means :*

*The user with user_id "112108" has placed an order with order_id "1" . The product "Bulgarian Yogurt" (product_id: 49302) is the first item in the cart. It is categorized under the "yogurt" aisle (aisle_id: 120) within the "dairy eggs" department (department_id: 16).*

*This isn't the user's first time ordering this product. It is the 4th order sequence for the user. The day of the week on which the order was placed is "4", the hour of the day on which the order was placed is "10". It has been 9 days since the user's previous order.*

```{r}
count_aisle = 
  count(instacart,aisle)|>
  arrange(-n)

  head(count_aisle,n=1)
nrow(count_aisle)
```

*There are `r nrow(count_aisle)` aisles, the most items are ordered from the aisle fresh vegetables.*

```{r}
count_aisle |>
  filter(n > 10000)|>
  mutate(aisle = fct_reorder(aisle, -n))|>
  ggplot(aes(x=aisle, y=n))+ 
  geom_col() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Items ordered from each aisle", x = "Aisle", y = "Number of items")
```

*This is a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered.*

```{r}
top_items = instacart |>
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |>
  group_by(aisle, product_name) |>
  summarize(times_ordered = n()) |>
  arrange(aisle, -times_ordered) |>
  slice_head(n = 3) |>
  knitr::kable()
``` 

`r top_items`

*This is a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.*

```{r}
mean_hour = instacart |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
               names_from = order_dow, values_from = mean_hour
  )|>
    knitr::kable()
```

`r mean_hour`

*This is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.*


## problem 2

```{r}
library(p8105.datasets)
data("brfss_smart2010") 
```

```{r}
brfss_df <- brfss_smart2010 |>
  janitor::clean_names() |>
  filter( topic== "Overall Health",
          response %in% c("Excellent","Very good","Good","Fair","Poor")
            ) |>
  mutate(response = factor(response, 
                           levels =c("Poor", "Fair", "Good", "Very good", "Excellent"))
         )
```


```{r}
brfss_df |>
  group_by(year, locationabbr) |>
  summarize(n_locations = n_distinct(locationdesc)) |>
   filter(year == 2002, n_locations >= 7) |>
    arrange(-n_locations)
```

*In 2002, states observed at 7 or more locations were PA, MA, NJ, CT, FL, NC. PA has the most observed locations as 10.*

```{r}
brfss_df |>
  group_by(year, locationabbr) |>
  summarize(n_locations = n_distinct(locationdesc)) |>
   filter(year == 2010, n_locations >= 7) |>
    arrange(-n_locations)
```

*In 2010, states observed at 7 or more locations were FL, NJ, TX, CA, MD, NC, NE, WA, MA, NY, OH, CO, PA,SC. FL has the most observed locations as 41.*

Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state:

```{r}
  brfss_df|>
  filter(response == "Excellent") |>
  group_by(year,locationabbr)|>
  summarize(mean_data_value = mean(data_value, na.rm= TRUE)) |>    
  ggplot(aes(x=year,y=mean_data_value,group=locationabbr,color=locationabbr))+
  geom_line()+
  labs(x = "Year", y = "Average of the data value", title = "“spaghetti” plot of this average value over time within a state ")
```

*This is a “spaghetti” plot of this average value over time within a state limited to Excellent responses. At a glance, there appears to be a consistent trend across states.*

*However, due to the sheer number of overlapping lines representing each state, distinguishing between them becomes challenging. This density impedes a clear and definitive interpretation of the data.*

Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY state:

```{r}
brfss_df |>
  filter(locationabbr == "NY", year %in% c(2006,2010))|>
  ggplot(aes(x = response, y =  data_value,fill=response)) +
  facet_grid(.~ year) +
  geom_boxplot()+
  labs(x = "Response", y = "Data Value", title = "Distribution of Data Value by Year in NY State") 
```

*This is a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY state. *

*For both years, the median ranking is as follows: 'Very good' holds the highest median, followed by 'Good', 'Excellent', 'Fair', and then 'Poor'.the distribution in the 'Very good' category is left-skewed,  the distribution in the 'Excellent' category is right-skewed.*

## problem 3

Load, tidy, merge, and otherwise organize the data sets:

```{r}
accel_df = read_csv("data/nhanes_accel.csv")|>
  janitor::clean_names()|>
   pivot_longer(
    cols = starts_with("min"),
               names_to = "Minute",
               values_to = "MIMS_value")

covar_df = read_csv("data/nhanes_covar.csv",skip = 4)|>
  janitor::clean_names() |>
  drop_na()|>
  filter(age >= 21)|>
  mutate(
      sex = case_match(
      sex,
      1 ~ "male",
      2 ~ "female"),
      education = case_match(
        education,
        1 ~ "less than high school",
        2 ~ "high school equivalent",
        3 ~ "more than high school"
      ))|>
  mutate(education = factor(education, levels=c("less than high school", "high school equivalent", "more than high school")))

final_df = inner_join(covar_df,accel_df,by="seqn")
```

Produce a reader-friendly table for the number of men and women in each education category:

```{r}
covar_df |>
  group_by(sex,education)|>
  summarize(n_obs=n())|>
  pivot_wider(
    names_from = education,
    values_from = n_obs
  )|>
  knitr::kable()
```

*The table indicates that the majority of both males and females have pursued education beyond high school. For females, most of them have more than high school education, followed by those with less than high school, and lastly, those with a high school equivalent. For males, the sequence is: more than high school, high school equivalent, and then less than high school.*

Create a visualization of the age distributions for men and women in each education category. 

```{r}
covar_df|>
  ggplot(aes(x=age,color=sex))+
  geom_density()+
  facet_grid(.~education)
```

*For individuals with an education level below high school:*

*The density plot shows the maximum density for age of females is within the 60-70 years old range. For males, it is within the 70-80 years range.*

*For those who have completed a high school-equivalent education:*

*The maximum density for age of females is within the 70-80  years old range. For males, it is within the 50-60 years range. years old range.*

*For individuals with an education level beyond high school:*

*The density plot indicates the maximum density for age of both females and males are within the 30-40 years old range.*

```{r}
total_activity_df = accel_df|>
  group_by(seqn)|>
  summarize(total_activity=sum(MIMS_value))
```


Plot - Total activity over the day:

```{r}
total_activity_plot_df = inner_join(covar_df,total_activity_df,by="seqn") 
total_activity_plot_df|>
  ggplot(aes(x=age,y=total_activity,color=sex))+
  facet_grid(.~education)+
  geom_point()+
  geom_smooth()+
   labs(title = "Total activity over the day by education level",
       x = "Age",
       y = "Activity Level",
       color = "Sex") 
```

*From the chart:*

*For those with an education level of less than high school, both males and females exhibit a pattern where total activity peaks at age 20, declines thereafter, rises again post 50, and starts declining after 60.*

*For individuals with a high school equivalent education, both genders see an increase in activity from age 20 to 40, followed by a decline. After 60, the decline for females becomes more gradual, while for males there's an upswing between 60-70 and then a downturn from 70-80.*

*For those educated beyond high school, males show a mild decline from age 20-50, an increase post 50, and then a sharp drop after 60. Females, on the other hand, begin with a decline, see a surge starting around age 40, and then experience another drop between 40-50.*

*In essence: While males and females within the same education levels display similar trends of rise and fall in activity, their peak times and inflection points differ.*

Plot - 24-hour activity time courses：

```{r}
final_df |>
  ggplot( aes(x = Minute, y = MIMS_value, color = sex)) +
  geom_point(alpha = 0.3)+
  geom_smooth() +
  facet_grid(.~education)+
  labs(title = "24-hour activity time courses by education level",
       x = "Minute",
       y = "Activity Level",
       color = "Sex") 
```

*From the observation:*

*In "high school equivalent" group, the 24-hour activity level distribution appears similar for both males and females. In the "less than high school" and "more than high school" groups, females exhibit a higher activity level compared to males. Moreover, all groups demonstrate a trend of rise-fall-rise-fall in their activity levels.*
